<!doctype html><html lang="en"><head><meta charset="utf-8"><link rel="preload" href="https://fonts.googleapis.com/css2?display=swap&amp;family=Libre+Baskerville:ital@0;1&amp;family=Libre+Franklin:wght@700&amp;family=DM+Mono" as="style"><link rel="preload" href="https://fonts.gstatic.com/s/librebaskerville/v9/kmKnZrc3Hgbbcjq75U4uslyuy4kn0qNZaxMaC82U.woff2" as="font" crossorigin="anonymous"><link rel="preload" href="https://fonts.gstatic.com/s/librefranklin/v6/jizOREVItHgc8qDIbSTKq4XkRg8T88bjFuXOnduhycKkANDPTedX18mE.woff" as="font" crossorigin="anonymous"><link rel="preload" href="https://fonts.gstatic.com/s/dmmono/v3/aFTU7PB1QTsUX8KYthqQBK6PYK0.woff2" as="font" crossorigin="anonymous"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><meta name="viewport" content="width=device-width,initial-scale=1"><title>Shuhei Kagawa</title><link rel="icon" sizes="16x16 32x32 48x48" href="/favicon.ico"><link rel="alternate" type="application/rss+xml" title="RSS Feed for shuheikagawa.com" href="/blog/feed/rss.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-309586-8', 'shuheikagawa.com');
      ga('send', 'pageview');</script><style>:root{--bg-color:#f9f9f9;--text-color:#222;--highlight-color:#095ae8;--code-text-color:var(--code-mono-1);--code-bg-color:#fff;--syntax-hue:230;--syntax-saturation:1%;--syntax-brightness:100%;--code-mono-1:hsl(var(--syntax-hue), 8%, 24%);--code-mono-2:hsl(var(--syntax-hue), 6%, 44%);--code-mono-3:hsl(var(--syntax-hue), 4%, 64%);--code-hue-1:hsl(198, 99%, 37%);--code-hue-2:hsl(221, 76%, 47%);--code-hue-3:hsl(301, 63%, 40%);--code-hue-4:hsl(119, 72%, 31%);--code-hue-5:hsl(5, 68%, 48%);--code-hue-5-2:hsl(344, 84%, 43%);--code-hue-6:hsl(41, 99%, 30%);--code-hue-6-2:hsl(41, 99%, 30%);--body-font-family:"Libre Baskerville",serif;--heading-font-family:"Libre Franklin",sans-serif;--code-font-family:"DM Mono",monospace}body{font-family:"Libre Baskerville",serif;font-family:var(--body-font-family);background:#f9f9f9;background:var(--bg-color);color:#222;color:var(--text-color);padding:0;margin:0;font-size:16px;line-height:1.9}.container{width:700px;padding:0 20px;margin:0 auto}a{color:#095ae8;color:var(--highlight-color);transition:color .5s ease;text-decoration:none}a:hover{text-decoration:underline}.header{padding:1.5em 0 1em;display:flex}.header__title{margin:0 10px 0 0;flex-grow:1;font-size:1em;font-weight:400}.header__title a{color:#222;color:var(--text-color)}.header__nav{flex-grow:0}.menu{list-style-position:outside;list-style-type:none;padding:0;margin:0;text-align:right}.menu__item{display:inline-block;padding:0 0 0 .7em}.menu__item a{color:#222;color:var(--text-color)}.footer{padding:3em 0 4em;text-align:center}.title{font-family:"Libre Franklin",sans-serif;font-family:var(--heading-font-family);font-size:3em;margin:0 0 .2em;line-height:1.1}.title a{color:#222;color:var(--text-color);text-decoration:none}.post,.post-list{padding:1.7em 0 1.25em}.post:not(:first-child):before{content:"* * *";font-family:"Libre Franklin",sans-serif;font-family:var(--heading-font-family);font-weight:700;font-size:4em;display:block;margin:.2em auto .6em;text-align:center;line-height:1}.post .meta{font-size:.75em}.post-list .title{margin-bottom:10px}.post-list-item{line-height:1.6em;padding:10px 0;display:flex}.post-list-item__date{font-size:.8em;width:8em;flex-shrink:0}.post-list-item__title{font-size:1.3em;margin:0;font-family:"Libre Franklin",sans-serif;font-family:var(--heading-font-family);font-weight:700}.post-list-item__title a{text-decoration:none;color:#222;color:var(--text-color)}.content h2,.content h3,.content h4,.content h5,.content h6{font-family:"Libre Franklin",sans-serif;font-family:var(--heading-font-family);margin:1em 0 0 0}.content h2{font-size:2.2em;line-height:1.1}.content h3{font-size:1.6em;line-height:1.3}.content h4{font-size:1.2em}.content img{max-width:100%;height:auto}.content p{margin:1.15em 0}.img-wrapper{display:block;text-align:center}.comments{margin-bottom:3em}ol,ul{list-style-position:outside;padding-left:1.4em}.table-wrapper{overflow-x:auto;margin:1.15em 0}.table-wrapper table{border-collapse:collapse;margin:0;width:100%}tr{vertical-align:top}th{font-weight:400;text-align:left}tbody{border-top:1px solid #333;border-bottom:1px solid #333;padding:.5em 0}td,th{padding-right:1em}code{color:#383942;color:var(--code-text-color);background-color:#fff;background-color:var(--code-bg-color);font-size:.9em;font-family:"DM Mono",monospace;font-family:var(--code-font-family)}.code__filename{display:inline-block;margin-bottom:13px;padding:5px 10px;font-size:.85em;background-color:#666}.hljs{display:block;line-height:1.5em;padding:1em 20px;overflow-x:auto;-webkit-overflow-scrolling:touch;color:#383942;color:var(--code-text-color);background-color:#fff;background-color:var(--code-bg-color)}.hljs-comment,.hljs-quote{color:#696b76;color:var(--code-mono-2);font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a625a4;color:var(--code-hue-3)}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#cd3527;color:var(--code-hue-5)}.hljs-literal{color:#0083bb;color:var(--code-hue-1)}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#188716;color:var(--code-hue-4)}.hljs-built_in,.hljs-class .hljs-title{color:#986800;color:var(--code-hue-6-2)}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986800;color:var(--code-hue-6)}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#1c56d2;color:var(--code-hue-2)}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}blockquote{font-style:italic;padding:0 0 0 2em;margin:1.5em 0}blockquote p:first-child:before{content:open-quote;font-family:serif;font-size:3em;font-weight:700;line-height:.1em;margin-right:.2em;vertical-align:-.4em}blockquote cite{color:#999990}blockquote cite:before{content:"- "}.pagination{list-style-position:outside;list-style-type:none;padding:0;margin-top:20px;display:flex;justify-content:space-between}.pagination li{min-height:1em}.pagination a{text-decoration:none}.pagination__next-page,.pagination__prev-page{width:35%}.pagination__next-page{text-align:right}.pagination__archives{flex-grow:1;text-align:center}@media only screen and (max-width:767px){body{font-size:15px;line-height:1.65}.container{width:auto}.post,.post-list{padding-top:10px}.post-list-item{display:block}.hljs{margin-left:-20px;margin-right:-20px;padding:1.4em 20px;border-radius:0}li .hljs{margin-left:0}.img-wrapper{margin-left:-20px;margin-right:-20px}}</style><link rel="stylesheet" href="https://fonts.googleapis.com/css2?display=swap&amp;family=Libre+Baskerville:ital@0;1&amp;family=Libre+Franklin:wght@700&amp;family=DM+Mono"><meta name="description" content="A personal website of Shuhei Kagawa. I write mostly on web technologies and life."><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@shuheikagawa"><meta property="og:title" content="Shuhei Kagawa"><meta property="og:site_name" content="Shuhei Kagawa"><meta property="og:description" content="A personal website of Shuhei Kagawa. I write mostly on web technologies and life."></head><body><div class="container"><header class="header"><h1 class="header__title"><a href="/">Shuhei Kagawa</a></h1><nav class="header__nav"><ul class="menu"><li class="menu__item"><a href="/about/">About</a></li><li class="menu__item"><a href="/blog/archives/">All posts</a></li></ul></nav></header><div class="main"><div class="post"><div class="post-header"><h1 class="title"><a href="/blog/2017/05/27/memory-usage/">Getting memory usage in Linux and Docker</a></h1><div class="meta"><span class="date">May 27, 2017</span> - Linux, Docker</div></div><div class="content"><div><p>Recently I started monitoring a Node.js app that we have been developing at work. After a while, I found that its memory usage % was growing slowly, like 20% in 3 days. The memory usage was measured in the following Node.js code.</p><pre><code class="hljs js"><span class="hljs-keyword">const</span> os = <span class="hljs-built_in">require</span>(<span class="hljs-string">"os"</span>);

<span class="hljs-keyword">const</span> total = os.totalmem();
<span class="hljs-keyword">const</span> free = os.freemem();
<span class="hljs-keyword">const</span> usage = ((free - total) / total) * <span class="hljs-number">100</span>;
</code></pre><p>So, they are basically from OS, which was <a href="https://alpinelinux.org/">Alpine Linux</a> on Docker in this case. Luckily I also had memory usages of application processes recorded, but they were not increasing. Then why is the OS memory usage increasing?</p><h2>Buffers and cached memory</h2><p>I used <code>top</code> command with <code>Shift+m</code> (sort by memory usage) and compared processes on a long-running server and ones on a newly deployed server. Processes on each side were almost same. The only difference was that <code>buffers</code> and <code>cached Mem</code> were high on the long-running one.</p><p>After some research, or googling, I concluded that it was not a problem. Most of <code>buffers</code> and <code>cached Mem</code> are given up when application processes claim more memory.</p><p>Actually <code>free -m</code> command provides a row for <code>used</code> and <code>free</code> taking buffers and cached into consideration.</p><pre><code class="hljs console"><span class="hljs-meta">$</span><span class="bash"> free -m</span>
             total  used  free  shared  buffers cached
Mem:          3950   285  3665     183       12    188
-/+ buffers/cache:    84  3866
Swap:         1896     0  1896
</code></pre><p>So, what are they actually? According to <a href="http://man7.org/linux/man-pages/man5/proc.5.html">the manual of <code>/proc/meminfo</code></a>, which is a pseudo file and the data source of <code>free</code>, <code>top</code> and friends:</p><pre><code class="hljs">Buffers %lu
       Relatively temporary storage for raw disk blocks that
       shouldn't get tremendously large (20MB or so).

Cached %lu
       In-memory cache for files read from the disk (the page
       cache).  Doesn't include SwapCached.
</code></pre><p>I am still not sure what exactly <code>Buffers</code> contains, but it contains metadata of files, etc. and it's relatively trivial in size. <code>Cached</code> contains cached file contents, which are called page cache. OS keeps page cache while RAM has enough free space. That was why the memory usage was increasing even when processes were not leaking memory.</p><p>If you are interested, <a href="https://www.quora.com/What-is-the-difference-between-Buffers-and-Cached-columns-in-proc-meminfo-output">What is the difference between Buffers and Cached columns in /proc/meminfo output?</a> on Quora has more details about <code>Buffers</code> and <code>Cached</code>.</p><h2>MemAvailable</h2><p>So, should we use <code>free + buffers + cached</code>? <code>/proc/meminfo</code> has an even better metric called <code>MemAvailable</code>.</p><pre><code class="hljs console">MemAvailable %lu (since Linux 3.14)
       An estimate of how much memory is available for
       starting new applications, without swapping.
</code></pre><pre><code class="hljs console"><span class="hljs-meta">$</span><span class="bash"> cat /proc/meminfo</span>
MemTotal:        4045572 kB
MemFree:         3753648 kB
MemAvailable:    3684028 kB
Buffers:           13048 kB
Cached:           193336 kB
...
</code></pre><p>Its background is explained well in <a href="https://github.com/torvalds/linux/commit/34e431b0ae398fc54ea69ff85ec700722c9da773">the commit in Linux Kernel</a>, but essentially it excludes non-freeable page cache and includes reclaimable slab memory. <a href="https://github.com/torvalds/linux/blob/v4.12-rc2/mm/page_alloc.c#L4341-L4382">The current implementation in Linux v4.12-rc2</a> still looks almost same.</p><p>Some implementation of <code>free -m</code> have <code>available</code> column. For example, on Boot2Docker:</p><pre><code class="hljs console"><span class="hljs-meta">$</span><span class="bash"> free -m</span>
       total  used  free  shared  buff/cache  available
Mem:    3950    59  3665     183         226       3597
Swap:   1896     0  1896
</code></pre><p>It is also <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html">available on AWS CloudWatch metrics</a> via <code>--mem-avail</code> flag.</p><h2>Some background about Docker</h2><p>My another question was &quot;Are those metrics same in Docker?&quot;. Before diving into this question, let's check how docker works.</p><p>According to <a href="https://docs.docker.com/engine/docker-overview/#the-underlying-technology">Docker Overview: The Underlying Technology</a>, processes in a Docker container directly run in their host OS without any virtualization, but they are isolated from the host OS and other containers in effect thanks to these Linux kernel features:</p><ul><li><a href="https://en.wikipedia.org/wiki/Linux_namespaces">namespaces</a>: Isolate PIDs, hostnames, user IDs, network accesses, IPC, etc.</li><li><a href="https://en.wikipedia.org/wiki/Cgroups">cgroups</a>: Limit resource usage</li><li><a href="https://en.wikipedia.org/wiki/UnionFS">UnionFS</a>: Isolate file system</li></ul><p>Because of the namespaces, <code>ps</code> command lists processes of Docker containers in addition to other processes in the host OS, while it cannot list processes of host OS or other containers in a docker container.</p><p><a href="https://docs.docker.com/engine/admin/resource_constraints/#memory">By default, Docker containers have no resource constraints</a>. So, if you run one container in a host and don't limit resource usage of the container, and this is my case, the container's &quot;free memory&quot; is same as the host OS's &quot;free memory&quot;.</p><h2>Memory metrics on Docker container</h2><p>If you want to monitor a Docker container's memory usage from outside of the container, it's easy. You can use <code>docker stats</code>.</p><pre><code class="hljs console"><span class="hljs-meta">$</span><span class="bash"> docker stats</span>
CONTAINER     CPU %  MEM USAGE / LIMIT  MEM %  NET I/O     BLOCK I/O  PIDS
fc015f31d9d1  0.00%  220KiB / 3.858GiB  0.01%  1.3kB / 0B  0B / 0B    2
</code></pre><p>But if you want to get the memory usage in the container or get more detailed metrics, it gets complicated. <a href="https://fabiokung.com/2014/03/13/memory-inside-linux-containers/">Memory inside Linux containers</a> describes the difficulties in details.</p><p><code>/proc/meminfo</code> and <code>sysinfo</code>, which is used by <code>os.totalmem()</code> and <code>os.freemem()</code> of Node.js, are not isolated, you get metrics of host OS if you use normal utilities like <code>top</code> and <code>free</code> in a Docker container.</p><p>To get metrics specific to your Docker container, <a href="https://docs.docker.com/engine/admin/runmetrics/">you can check pseudo files in <code>/sys/fs/cgroup/memory/</code></a>. They are not standardized according to <a href="https://fabiokung.com/2014/03/13/memory-inside-linux-containers/">Memory inside Linux containers</a> though.</p><pre><code class="hljs console"><span class="hljs-meta">$</span><span class="bash"> cat /sys/fs/cgroup/memory/memory.usage_in_bytes</span>
303104
<span class="hljs-meta">$</span><span class="bash"> cat /sys/fs/cgroup/memory/memory.limit_in_bytes</span>
9223372036854771712
</code></pre><p><code>memory.limit_in_bytes</code> returns a very big number if there is no limit. In that case, you can find the host OS's total memory with <code>/proc/meminfo</code> or commands that use it.</p><h2>Conclusion</h2><p>It was a longer journey than I initially thought. My takeaways are:</p><ul><li>Available Memory &gt; Free Memory</li><li>Use <code>MemAvailable</code> if available (pun intended)</li><li>Processes in a Docker container run directly in host OS</li><li>Understand what you are measuring exactly, especially in a Docker container</li></ul></div></div></div><div class="post"><div class="post-header"><h1 class="title"><a href="/blog/2017/05/13/http-request-timeouts-in-javascript/">HTTP request timeouts in JavaScript</a></h1><div class="meta"><span class="date">May 13, 2017</span> - JavaScript, Node.js</div></div><div class="content"><div><p>These days I have been working on a Node.js front-end server that calls back-end APIs and renders HTML with React components. In this microservices setup, I am making sure that the server doesn't become too slow even when its dependencies have problems. So I need to set timeouts to the API calls so that the server can give up non-essential dependencies quickly and fail fast when essential dependencies are out of order.</p><p>As I started looking at timeout options carefully, I quickly found that there were many different kinds of timeouts even in the very limited field, HTTP request with JavaScript.</p><h2>Node.js <code>http</code> and <code>https</code></h2><p>Let's start with the standard library of Node.js. <code>http</code> and <code>https</code> packages provide <code>request()</code> function, which makes a HTTP(S) request.</p><h3>Timeouts on <code>http.request()</code></h3><p><a href="http://nodejs.org/api/http.html#http_http_request_options_callback"><code>http.request()</code></a> takes a <code>timeout</code> option. Its documentation says:</p><blockquote><p><code>timeout</code> <code>&lt;number&gt;</code>: A number specifying the socket timeout in milliseconds. This will set the timeout before the socket is connected.</p></blockquote><p>So what does it actually do? It internally calls <code>net.createConnection()</code> with its <code>timeout</code> option, which eventually calls <code>socket.setTimeout()</code> before the socket starts connecting.</p><p>There is also <a href="http://nodejs.org/api/http.html#http_request_settimeout_timeout_callback"><code>http.ClientRequest.setTimeout()</code></a>. Its documentation says:</p><blockquote><p>Once a socket is assigned to this request and is connected <code>socket.setTimeout()</code> will be called.</p></blockquote><p>So this also calls <a href="http://nodejs.org/api/net.html#net_socket_settimeout_timeout_callback"><code>socket.setTimeout()</code></a>.</p><p>Either of them doesn't close the connection when the socket timeouts but only emits a <code>timeout</code> event.</p><p>So, what does <code>socket.setTimeout()</code> do? Let's check.</p><h3>net.Socket.setTimeout()</h3><p><a href="http://nodejs.org/api/net.html#net_socket_settimeout_timeout_callback">The documentation</a> says:</p><blockquote><p>Sets the socket to timeout after timeout milliseconds of inactivity on the socket. By default <code>net.Socket</code> does not have a timeout.</p></blockquote><p>OK, but what does &quot;inactivity on the socket&quot; exactly mean? In a happy path, a TCP socket follows the following steps:</p><ol><li>Start connecting</li><li>DNS lookup is done: <code>lookup</code> event (Doesn't happen in HTTP Keep-Alive)</li><li>Connection is made: <code>connect</code> event (Doesn't happen in HTTP Keep-Alive)</li><li>Read data or write data</li></ol><p>When you call <code>socket.setTimeout()</code>, a timeout timer is created and restarted before connecting, after <code>lookup</code>, after <code>connect</code> and each data read &amp; write. So the <code>timeout</code> event is emitted on one of the following cases:</p><ul><li>DNS lookup doesn't finish in the given timeout</li><li>TCP connection is not made in the given timeout after DNS lookup</li><li>No data read or write in the given timeout after connection, previous data read or write</li></ul><p>This might be a bit counter-intuitive. Let's say you called <code>socket.setTimeout(300)</code> to set the timeout as 300 ms, and it took 100 ms for DNS lookup, 100 ms for making a connection with a remote server, 200 ms for the remote server to send response headers, 50 ms for transferring the first half of the response body and another 50 ms for the rest. While the entire request &amp; response took more than 500 ms, <code>timeout</code> event is not emitted at all.</p><p>Because the timeout timer is restarted in each step, timeout happens only when a step is not completed in the given time.</p><p>Then what happens if timeouts happen in all of the steps? As far as I tried, <code>timeout</code> event is triggered only once.</p><p>Another concern is HTTP Keep-Alive, which reuses a socket for multiple HTTP requests. What happens if you set a timeout for a socket and the socket is reused for another HTTP request? Never mind. <code>timeout</code> set in an HTTP request does not affect subsequent HTTP requests because <a href="https://github.com/nodejs/node/blob/v7.10.0/lib/_http_client.js#L546">the timeout is cleaned up when it's kept alive</a>.</p><h3>HTTP Keep-Alive &amp; TCP Keep-Alive</h3><p>This is not directly related to timeout, but I found Keep-Alive options in <code>http</code>/<code>https</code> are a bit confusing. They mix HTTP Keep-Alive and TCP Keep-Alive, which are completely different things but coincidentally have the same name. For example, the options of <a href="http://nodejs.org/api/http.html#http_new_agent_options"><code>http.Agent</code> constructor</a> has <code>keepAlive</code> for HTTP Keep-Alive and <code>keepAliveMsecs</code> for TCP Keep-Alive.</p><p>So, how are they different?</p><ul><li>HTTP Keep-Alive reuses a TCP connection for multiple HTTP requests. It saves the TCP connection overhead such as DNS lookup and TCP slow start.</li><li>TCP Keep-Alive closes invalid connections, and it is normally handled by OS.</li></ul><h3>So?</h3><p><code>http</code>/<code>https</code> use <code>socket.setTimeout()</code> whose timer is restarted in stages of socket lifecycle. It doesn't ensure a timeout for the overall request &amp; response. If you want to make sure that a request completes in a specific time or fails, you need to prepare your own timeout solution.</p><h2>Third-party modules</h2><h3><code>request</code> module</h3><p><a href="https://github.com/request/request">request</a> is a very popular HTTP request library that supports many convenient features on top of <code>http</code>/<code>https</code> module. Its README says:</p><blockquote><p><code>timeout</code> - Integer containing the number of milliseconds to wait for a server to send response headers (and start the response body) before aborting the request.</p></blockquote><p>However, as far as I checked the implementation, <code>timeout</code> is not applied to the timing of response headers as of v2.81.1.</p><p>Currently this module emits the two types of timeout errors:</p><ul><li><code>ESOCKETTIMEDOUT</code>: Emitted from <code>http.ClientRequest.setTimeout()</code> described above, which uses <code>socket.setTimeout()</code>.</li><li><code>ETIMEDOUT</code>: Emitted when a connection is not established in the given timeout. It was applied to the timing of response headers before v2.76.0.</li></ul><p>There is <a href="https://github.com/request/request/issues/2535">a GitHub issue</a> for it, but I'm not sure if it's intended and the README is outdated, or it's a bug.</p><p>By the way, <code>request</code> provides a useful timing measurement feature that you can enable with <code>time</code> option. It will help you to define a proper timeout value.</p><h3><code>axios</code> module</h3><p><a href="https://github.com/mzabriskie/axios"><code>axios</code></a> is another popular library that uses <code>Promise</code>. Like <code>request</code> module's README, its <code>timeout</code> option timeouts if the response status code and headers don't arrive in the given timeout.</p><h2>Browser APIs</h2><p>While my initial interest was server-side HTTP requests, I become curious about browser APIs as I was investigating Node.js options.</p><h3>XMLHttpRequest</h3><p><a href="http://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/timeout"><code>XMLHttpRequest.timeout</code></a> aborts a request after the given timeout and calls <code>ontimeout</code> event listeners. The documentation does not explain the exact timing, but I guess that it is until <code>readyState === 4</code>, which means that the entire response body has arrived.</p><h3>fetch()</h3><p>As far as I read <a href="https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch"><code>fetch()</code>'s documentation on MDN</a>, it does not have any way to specify a timeout. So we need to handle by ourselves. We can do that easily using <a href="http://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/race"><code>Promise.race()</code></a>.</p><pre><code class="hljs js"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">withTimeout</span>(<span class="hljs-params">msecs, promise</span>) </span>{
  <span class="hljs-keyword">const</span> timeout = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function">(<span class="hljs-params">resolve, reject</span>) =&gt;</span> {
    setTimeout(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> {
      reject(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">"timeout"</span>));
    }, msecs);
  });
  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Promise</span>.race([timeout, promise]);
}

withTimeout(<span class="hljs-number">1000</span>, fetch(<span class="hljs-string">"https://foo.com/bar/"</span>))
  .then(doSomething)
  .catch(handleError);
</code></pre><p>This kind of external approach works with any HTTP client and timeouts for the overall request and response. However, it does not abort the underlying HTTP request while preceding timeouts actually abort HTTP requests and save some resources.</p><h2>Conclusion</h2><p>Most of the HTTP request APIs in JavaScript doesn't offer timeout mechanism for the overall request and response. If you want to limit the maximum processing time for your piece of code, you have to prepare your own timeout solution. However, if your solution relies on a high-level abstraction like <code>Promise</code> and cannot abort underlying TCP socket and HTTP request when timeout, it is nice to use an existing low-level timeout mechanisms like <code>socket.setTimeout()</code> together to save some resources.</p></div></div></div><div class="post"><div class="post-header"><h1 class="title"><a href="/blog/2017/01/05/main-jsnext-main-and-module/">main, jsnext:main and module</a></h1><div class="meta"><span class="date">Jan 5, 2017</span> - JavaScript</div></div><div class="content"><div><p>Node module's <code>package.json</code> has <code>main</code> property. It's the entry point of a package, which is exported when a client <code>require</code>s the package.</p><p>Recently, I got <a href="https://github.com/shuhei/material-colors/issues/13">an issue</a> on one of my popular GitHub repos, <code>material-colors</code>. It claimed that &quot;colors.es2015.js const not supported in older browser (Safari 9)&quot;, which looked pretty obvious to me. ES2015 is a new spec. Why do older browsers support it?</p><p>I totally forgot about it at the time, but <a href="https://github.com/shuhei/material-colors/pull/10">the <code>colors.es2015.js</code> was exposed as the npm package's <code>jsnext:main</code></a>. And to my surprise, it turned out that <em><code>jsnext:main</code> shouldn't have <em>jsnext</em> or ES2015+ features</em> like <code>const</code>, arrow function and <code>class</code>. What a contradiction!</p><h2>jsnext:main</h2><p>Module bundlers that utilizes tree shaking to reduce bundle size, like Rollup and Webpack 2, require packages to expose ES Modules with <code>import</code> and <code>export</code>. So they invented a non-standard property called <code>jsnext:main</code>.</p><p>However, it had a problem. If the file specified <code>jsnext:main</code> contains ES2015+ features, it won't run without transpilation on browsers that don't support those features. But normally people don't transpile packages in <code>node_modules</code>, and many issues were created on GitHub. To solve the problem, people concluded that <code>jsnext:main</code> shouldn't have ES2015+ features other than <code>import</code> and <code>export</code>. What an irony.</p><h2>module</h2><p>Now the name <code>jsnext:main</code> is too confusing. I was confused at least. People discussed for a better name, and <a href="https://github.com/rollup/rollup/wiki/pkg.module"><code>module</code></a> came out that <a href="https://github.com/rollup/rollup/wiki/jsnext:main">supersedes <code>jsnext:main</code></a>. And <a href="https://nodesource.com/blog/es-modules-and-node-js-hard-choices/">it might be standardized</a>.</p><h2>So?</h2><p>I looked into a couple of popular repos, and they had both of <code>jsnext:main</code> and <code>module</code> in addition to <code>main</code>.</p><ul><li><a href="https://github.com/reactjs/redux/blob/master/package.json">redux</a></li><li><a href="https://github.com/mrdoob/three.js/blob/dev/package.json">three.js</a></li></ul><p>At this time, it seems to be a good idea to have both of them if you want to support tree shaking. If you don't, just go with only the plain old <code>main</code>.</p></div></div></div><ul class="pagination"><li class="pagination__prev-page"><a href="/blog/pages/6/">Newer posts</a></li><li class="pagination__archives"><a href="/blog/archives/">All posts</a></li><li class="pagination__next-page"><a href="/blog/pages/8/">Older posts</a></li></ul></div><footer class="footer">© Shuhei Kagawa</footer></div></body></html>